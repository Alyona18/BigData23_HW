{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Напишите программу, которая находит самое длинное слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest word: землемерно-таксаторские\n"
     ]
    }
   ],
   "source": [
    "sc.stop()\n",
    "conf = SparkConf().setAppName(\"LongestWord\").setMaster(\"local\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "data = sc.textFile(\"D:/big-data-2023/alms-bd-2023-3cecad0d39f8/data/wiki.txt\")\n",
    "\n",
    "longest_word = (\n",
    "    data.flatMap(lambda line: line.replace('\\t', ' ').split(\" \"))\n",
    "    .reduce(lambda x, y: x if len(x) > len(y) and x.find('http') == -1 and x.find('.') == -1 else y)\n",
    ")\n",
    "\n",
    "print(\"Longest word:\", longest_word)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Напишите программу, которая находит среднюю длину слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length: 6.582369447100479\n"
     ]
    }
   ],
   "source": [
    "avg_word_length = (\n",
    "    data.flatMap(lambda line: line.split(\" \"))\n",
    "    .map(lambda word: (len(word), 1))\n",
    "    .reduce(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    ")\n",
    "\n",
    "avg_word_length = avg_word_length[0] / avg_word_length[1]\n",
    "print(\"Average word length:\", avg_word_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Напишите программу, которая находит самое частоупотребляемое слово, состоящее из латинских букв."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent word: ru\n"
     ]
    }
   ],
   "source": [
    "words = (\n",
    "    data.flatMap(lambda line: re.findall(r'\\b[a-zA-Z]+\\b', line))\n",
    "    .map(lambda word: word.lower())\n",
    ")\n",
    "\n",
    "most_frequent_word = words.map(lambda word: (word, 1)).reduceByKey(lambda x, y: x + y).max(lambda x: x[1])[0]\n",
    "\n",
    "print(\"Most frequent word:\", most_frequent_word)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Все слова, которые более чем в половине случаев начинаются с большой буквы и встречаются больше 10 раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = data.flatMap(lambda line: line.split(\" \"))\n",
    "# считаем количество вхождений каждого слова\n",
    "capitalized_words = words.filter(lambda word: len(word) > 0 and word[0].isupper())\n",
    "\n",
    "word_counts = capitalized_words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# находим общее количество слов\n",
    "total_words = capitalized_words.count()\n",
    "\n",
    "# фильтруем слова, которые встречаются больше 10 раз и начинаются с большой буквы в более, чем половине случаев\n",
    "result = word_counts.filter(lambda pair: pair[1] > 10 and (pair[0][0].isupper() and pair[1] / total_words > 0.5)).collect()\n",
    "\n",
    "# выводим результат\n",
    "for word, count in result:\n",
    "    print(word)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Напишите программу, которая с помощью статистики определяет устойчивые сокращения вида `пр.`, `др.`, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ед.\n",
      "кв.\n",
      "мн.\n",
      "ст.\n",
      "ок.\n",
      "см.\n",
      "фр.\n"
     ]
    }
   ],
   "source": [
    "sc.stop()\n",
    "conf = SparkConf().setAppName(\"Stable Abbreviations\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# загружаем текстовый файл и разбиваем его на слова\n",
    "words = sc.textFile(\"D:/big-data-2023/alms-bd-2023-3cecad0d39f8/data/wiki.txt\").flatMap(lambda line: line.split(\" \"))\n",
    "\n",
    "# фильтруем слова, чтобы оставить только те, которые содержат сокращения\n",
    "abbreviations = (words.flatMap(lambda line: re.findall(r'\\b[а-яА-Я]+\\.\\b', line)).filter(lambda word: len(word) == 3 and word.find('.') != -1 and word[:-1].isalpha()))\n",
    "\n",
    "# считаем количество вхождений каждого сокращения\n",
    "abbreviation_counts = abbreviations.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# считаем общее количество слов\n",
    "total_words = words.count()\n",
    "\n",
    "# фильтруем сокращения, которые встречаются более 10 раз и составляют более 0.1% от общего количества слов\n",
    "result = abbreviation_counts.filter(lambda pair: pair[1] > 10 and pair[1] / total_words > 0.0000001).collect()\n",
    "\n",
    "# выводим результат\n",
    "for abbreviation, count in result:\n",
    "    print(abbreviation)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Напишите программу, которая с помощью статистики определяет устойчивые сокращения вида  `т.п.`, `н.э.`, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "т.д\n",
      "г.г\n",
      "т.к\n",
      "т.н\n",
      "л.с\n",
      "с.ш\n",
      "в.д\n",
      "А.А\n",
      "мн.ч\n",
      "т.е\n",
      "в.в\n",
      "н.э\n",
      "ю.ш\n",
      "г.р\n",
      "ед.ч\n",
      "В.В\n",
      "т.ч\n",
      "э.д\n",
      "кв.м\n",
      "А.И\n",
      "т.п\n",
      "В.И\n",
      "А.Ф\n"
     ]
    }
   ],
   "source": [
    "sc.stop()\n",
    "conf = SparkConf().setAppName(\"Stable Abbreviations\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# загружаем текстовый файл и разбиваем его на слова\n",
    "words = sc.textFile(\"D:/big-data-2023/alms-bd-2023-3cecad0d39f8/data/wiki.txt\").flatMap(lambda line: line.split(\" \"))\n",
    "\n",
    "# фильтруем слова, чтобы оставить только те, которые содержат сокращения\n",
    "abbreviations = (words.flatMap(lambda line: re.findall(r'\\b[а-яА-Я]+\\.+\\b[а-яА-Я]\\b', line)).filter(lambda word: word.find('.') != -1 and word.find('.') != (len(word)-1)))\n",
    "\n",
    "# считаем количество вхождений каждого сокращения\n",
    "abbreviation_counts = abbreviations.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# считаем общее количество слов\n",
    "total_words = words.count()\n",
    "\n",
    "# фильтруем сокращения, которые встречаются более 10 раз и составляют более 0.1% от общего количества слов\n",
    "result = abbreviation_counts.filter(lambda pair: pair[1] > 10 and pair[1] / total_words > 0.000001).collect()\n",
    "\n",
    "# выводим результат\n",
    "for abbreviation, count in result:\n",
    "    print(abbreviation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
